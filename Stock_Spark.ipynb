{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosvalenciano/Project4/blob/main/Stock_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_KW73O2e3dw",
        "outputId": "02ee9964-b7fa-47c6-a9e2-9cf8c0365234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,036 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,578 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [28.5 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,547 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,306 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,304 kB]\n",
            "Fetched 7,159 kB in 3s (2,145 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.4.0'\n",
        "spark_version = 'spark-3.5.0'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2XbWNf1Te5fM"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "import time\n",
        "import datetime as dt\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "wOJqxG_RPSwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c27c5e0-460f-44b1-a97f-9debee203860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------+-----------+-----------+-----------+---------+------------+------------+---------------+\n",
            "|      Date|       Open|       High|        Low|      Close|  Adj_Close|   Volume|company_name|Scaled_Close|predicted_close|\n",
            "+----------+-----------+-----------+-----------+-----------+-----------+---------+------------+------------+---------------+\n",
            "|2019-12-12|66.94499969|68.13999939|66.83000183|67.86499786|66.11624908|137310400|       APPLE| 0.045575656|    72.47750092|\n",
            "|2019-12-13|67.86499786|68.82499695|67.73249817|68.78749847|67.01499176|133587600|       APPLE| 0.048372223|    72.44999695|\n",
            "|2019-12-16|      69.25|70.19750214|69.24500275|69.96499634|68.16214752|128186000|       APPLE| 0.051941815|    72.87999725|\n",
            "|2019-12-17|69.89250183|70.44249725|69.69999695|70.10250092|68.29610443|114158400|       APPLE| 0.052358661|    73.41249847|\n",
            "|2019-12-18|69.94999695|70.47499847|69.77999878|69.93499756|68.13290405|116028400|       APPLE| 0.051850873|    75.08750153|\n",
            "|2019-12-19|     69.875|70.29499817|69.73750305|70.00499725|68.20111847| 98369200|       APPLE| 0.052063078|    74.35749817|\n",
            "|2019-12-20|70.55750275|70.66249847|69.63999939|69.86000061| 68.0598526|275978000|       APPLE|  0.05162352|    64.46804047|\n",
            "|2019-12-23|70.13249969|    71.0625|70.09249878|         71|69.17047882| 98572000|       APPLE| 0.055079435|    64.96473694|\n",
            "|2019-12-24|71.17250061|71.22250366|70.73000336|71.06749725|69.23622894| 48478800|       APPLE| 0.055284053|    65.37545776|\n",
            "|2019-12-26|71.20500183|72.49500275|71.17500305|72.47750092|70.60991669| 93121200|       APPLE| 0.059558488|    66.24635315|\n",
            "|2019-12-27|72.77999878|73.49250031|72.02999878|72.44999695|70.58312225|146266000|       APPLE|  0.05947511|    66.79875183|\n",
            "|2019-12-30|72.36499786|73.17250061|71.30500031|72.87999725|71.00204468|144114400|       APPLE| 0.060778659|    67.24473572|\n",
            "|2019-12-31|72.48249817|73.41999817|72.37999725|73.41249847|71.52080536|100805600|       APPLE| 0.062392939|    67.72517395|\n",
            "|2020-01-02|74.05999756|75.15000153|73.79750061|75.08750153|73.15264893|135480400|       APPLE| 0.067470722|    68.79457855|\n",
            "|2020-01-03|74.28749847|75.14499664|     74.125|74.35749817| 72.4414444|146322800|       APPLE| 0.065257712|    69.14817047|\n",
            "|2020-01-06|73.44750214|74.98999786|    73.1875|74.94999695|73.01867676|118387200|       APPLE| 0.067053876|    69.49097443|\n",
            "|2020-01-07|74.95999908|75.22499847|74.37000275|74.59750366|72.67528534|108872000|       APPLE|  0.06598529|    69.51239014|\n",
            "|2020-01-08|74.29000092|76.11000061|74.29000092|75.79750061|73.84435272|132079200|       APPLE| 0.069623088|    70.03868866|\n",
            "|2020-01-09|76.80999756|77.60749817|76.55000305|77.40750122|75.41287231|170108400|       APPLE| 0.074503816|    71.19089508|\n",
            "|2020-01-10|77.65000153|78.16750336|    77.0625|77.58249664|75.58335876|140644800|       APPLE| 0.075034315|    72.02346802|\n",
            "+----------+-----------+-----------+-----------+-----------+-----------+---------+------------+------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Read in the csv into a DataFrame.\n",
        "\n",
        "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Multiple_Stocks.csv\")\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RoljcJ7WPpnm"
      },
      "outputs": [],
      "source": [
        "# 2. Create a temporary view of the DataFrame.\n",
        "df.createOrReplaceTempView('stocks')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "L6fkwOeOmqvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad4d315-3a88-47d7-a443-a9b28e3850f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+\n",
            "|  Company|   Predicted_Close|\n",
            "+---------+------------------+\n",
            "|MICROSOFT|       373.3289693|\n",
            "|     META| 328.2066650333333|\n",
            "|    APPLE|194.51652016666665|\n",
            "|   AMAZON|       145.0767466|\n",
            "|   GOOGLE|133.76257833333332|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3.\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "  company_name AS Company,\n",
        "  (Avg(predicted_close)) AS Predicted_Close\n",
        "  FROM stocks\n",
        "  WHERE Date between ('2023-12-07') and ('2023-12-11')\n",
        "  GROUP BY Company\n",
        "  ORDER BY Predicted_Close DESC\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "l8p_tUS8h8it",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "814e72c1-e363-4154-88f9-4746f5ea0bb4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-df528199079d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 4. What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m spark.sql(\"\"\"\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mSELECT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcompany_name\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mCompany\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mClose\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mClose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.0-bin-hadoop3/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.0-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES] Cannot resolve \"(2023-12-07 AND 2023-12-11)\" due to data type mismatch: the left and right operands of the binary operator have incompatible types (\"DATE\" and \"STRING\").; line 6 pos 8;\n'Sort ['Predicted_Close DESC NULLS LAST], true\n+- 'Aggregate ['Company], ['company_name AS Company#1736, 'Close AS Close#1737]\n   +- 'Filter (cast(2023-12-07 as date) AND 2023-12-11)\n      +- SubqueryAlias stocks\n         +- View (`stocks`, [Date#1093,Open#1094,High#1095,Low#1096,Close#1097,Adj_Close#1098,Volume#1099,company_name#1100,Scaled_Close#1101,predicted_close#1102])\n            +- Relation [Date#1093,Open#1094,High#1095,Low#1096,Close#1097,Adj_Close#1098,Volume#1099,company_name#1100,Scaled_Close#1101,predicted_close#1102] csv\n"
          ]
        }
      ],
      "source": [
        "# 4. What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "  company_name AS Company,\n",
        "  Close AS Close\n",
        "  FROM stocks\n",
        "  WHERE Date ('2023-12-07') and ('2023-12-11')\n",
        "  GROUP BY Company\n",
        "  ORDER BY Predicted_Close DESC\n",
        "\"\"\").show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}